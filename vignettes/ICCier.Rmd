---
title: "ICCier"
author: "Stephen R. Martin"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
    toc: true
    readme: true
bibliography: bib.bib
csl: apa.csl
vignette: >
  %\VignetteIndexEntry{ICCier}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width=6,fig.height=4,
  message=FALSE,
  error=FALSE,
  warning=FALSE
)
```

# Introduction
`ICCier` is a package for estimating and predicting group-specific or observation-specific intraclass correlation coefficients (ICCs).
In this vignette, we describe the rationale for specific ICCs, and walk the reader through the package with various examples.
First, we provide some background on ICCs and their variety of forms.
In this section, we introduce the reader to the notation used throughout the rest of the vignette.
Second, we describe the notion and rationale for varying ICCs (e.g., group-specific ICCs).
Third, we describe the Bayesian mixed effects location scale model (MELSM) that underlies the estimation of these ICCs.
The MELSM is the "engine" that makes varying ICCs possible, and we encourage all readers to read this section to best understand the model output.
Fourth, we walk through the `ICCier` functions, followed by numerous examples for a variety of scenarios.
Finally, we end with some best practices and tips for using the `ICCier` package.

# Background
## Intraclass Correlation Coefficients
The intraclass correlation coefficient (ICC) is the proportion of total variance that is due to between-group variance.
It can also be thought of as a reliability estimate, or the expected correlation between any two scores within the same group.
In its most basic form, it can be expressed as:
$$
\text{ICC(1)} = \frac{\sigma^2_b}{\sigma^2_b + \sigma^2_{\epsilon}},
$$
where $\sigma^2_b$ is the variance between groups, and $\sigma^2_\epsilon$ is the residual variance.

The ICC ranges from 0 to 1, with 0 meaning none of the variance is due to between-group variation, and 1 meaning all is due to between-group variation.
The *groups* of data may be many things, such as trials within *persons*, persons within *schools*, regions within *countries*, and so on.
For example, if one has repeated trials within persons, and observes and ICC(1) of .45, then 45\% of the variance in the observations is due to differences between persons.

There are several ICCs, and `ICCier` supports many of them.
The ICC(1) is specified above, and represents the proportion of variability in the *observations* due to the grouping factor.
The ICC(2) represents the proportion of variability in the *mean score* estimates that is due to true group mean variability.
It is specified as:
$$
\text{ICC(2)} = \frac{\sigma^2_b}{\sigma^2_b + \frac{\sigma^2_\epsilon}{n}},
$$
where $n$ is the number of observations within each group.
The ICC(2) is the same as the ICC(1), except the second variance component is the squared standard error of the mean (i.e., the sampling variance of the mean).
When $n$ varies across group (i.e., unbalanced groups), it is common to estimate the expected sampling variance by using the average $n_i$ [E.g., See @Raudenbush2002].

Thus far, we have only described the *unconditional* ICC.
Unconditional ICCs describe the proportion of variance due to group-varying *means*.
In unconditional ICCs, $\sigma^2_b$ describes the variance of group means, and $\sigma^2_\epsilon$ is the within-group variance.
Conditional ICCs include a model on the expected values of the outcome.
That is, $\sigma^2_\epsilon$ is no longer the within-group variance, but the *residual variance* after accounting for the linear predictors.

Moreover, the $\sigma^2_b$ is ill-defined for conditional ICCs, because there is no longer a simple mean estimate for each group.
There are two broad approaches for the $\sigma^2_b$ in conditional ICCs.
One, which we call *unadjusted* (and is default in `ICCier`), replaces $\sigma^2_b$ with $\sigma^2_{u_0i}$, the variance of the *intercept*.
The corresponding ICC, labeled uICC(1), then represents the proportion of variance (after controlling for the predictors) due to groups, assuming the predictors are all at zero.
If one is interested in the ICC or reliability of conditional group means (i.e., the group means when the predictors are zero), then this is the conditional ICC of interest.

The second, which we call *adjusted* (and is used when `adjusted = TRUE`), replaces $\sigma^2_b$ with $\sigma^2_{\hat u_{ij}}$, the variance due to *all random coefficients*.
That is, $\hat u_{ij} = u_{0i} + x_{ij}u_{1i} + \ldots$, and $\sigma^2_b = \text{Var}(\hat u_{ij})$.
By comparison, the *unadjusted* conditional ICC merely uses $\sigma^2_b = \text{Var}(u_{0i})$.
This means that the aICC(1) represents the proportion of total residual variance that is due to group-specific variation, as a whole.
Alternatively stated, it represents the proportion of variance that is *predicted* by random effects.
If one is interested in individual differences (i.e., in intercepts and slopes), then this is the conditional ICC of interest.

When no random slopes are present, adjusted and unadjusted ICCs are equivalent.
The ICC(1) and ICC(2) can be estimated for unconditional models, and for *unadjusted* conditional models.

In sum, `ICCier` can handle unconditional and conditional ICCs with single grouping factors.
These include the ICC(1), ICC(2), uICC(1), uICC(2), and aICC(1).
This alone is not novel --- various packages permit the estimation of these ICCs.
`ICCier`, however, can estimate these quantities *per* group, and predict them *per* observation.
Consequently, `ICCier` can be used to probe sources of reliability.

## Group and observation-specific ICCs

# The Underlying Model
This section details the model as implemented in the \texttt{ICCier} package.
Let $y_{ij}$ be the $j$th observation in the $i$th group response vector $\Vector{y}_i$.
Because we are using an unconditional one-way model, the expected response for any $y_{ij}$ is $\mu_i = \beta_0 + u_{0i}$.
The expected residual standard deviation for $y_{ij}$ is log-linearly modeled from a Level 1 design matrix ($\Vector{x_i}$) and coefficient vector ($\Vector{\gamma}_i$).
All Level 1 scale coefficients are modeled using a multivariate linear model from a Level 2 design matrix ($\Vector{X}$), coefficient \emph{matrix} ($\Vector{\Gamma}$), and random effect row vectors ($\Vector{u}^{\sigma\intercal}_{i}$).
Here, $\Vector{X}_i$ is the row vector containing group-level predictors for group $i$.
All random effects ($u_{0i},\Vector{u}^\sigma_i$) are assumed to vary and covary.
The standard deviations of the random effects are similarly modeled using a multivariate linear model from a Level 2 design matrix, and coefficient matrix $\Vector{\eta}$.
Altogether, the model is defined as follows.
\begin{align*}
    \Vector{y}_{i} &\sim \mathcal{N}(\mu_{i}, \Vector{\hat\sigma}_{\epsilon,i}) \\
    \mu_{i} &= \beta_0 + u_{0i} \tag{Location Model} \\
    %\Vector{y}_{i} &= \beta_0 + u_{0i} + \Vector{e}_{i} \tag{Location Model}\\
    \log\Vector{\hat\sigma}_{\epsilon,i} &= \Vector{x}_{i}\Vector{\gamma}_{i} \tag{Level 1 Scale Model}\\
    %\Vector{e}_{i} &\sim \mathcal{N}(0,\Vector{\hat\sigma}_{\epsilon,i}) \\
    %\log\Vector{\hat\sigma}_{\epsilon,i} &= \Vector{x}_{i}\Vector{\gamma}_{i} \tag{Level 1 Scale Model}\\
    \Vector{\gamma}_{i}^\intercal &= \Vector{X}_{i}\Vector{\Gamma} + \Vector{u}^{\sigma\intercal}_i \tag{Level 2 Scale Model}\\
    \begin{bmatrix}
        u_{0i} \\
        \Vector{u}^{\sigma}_i
    \end{bmatrix} &\sim \mathcal{N}(\Vector{0},\Vector{\Sigma}_i = \Vector{\sigma}_i\Vector{\Omega}\Vector{\sigma}_i) \\
    \diag(\log\Vector{\sigma}_i)^\intercal &= \Vector{X}_i\Vector{\eta} \tag{Between-group Scale Model} 
%    \text{ICC(1)}_{ij} &= \frac{\exp(\Vector{X}_i\Vector{\eta}_{\bullet 1})^2}{\exp(\Vector{X}_i\Vector{\eta}_{\bullet 1})^2 + \exp(\Vector{x}_{ij}\Vector{\gamma}_i)^2}
\end{align*}
The expected unconditional ICC(1)$_{ij}$ is therefore
\begin{align*}
    \text{ICC(1)}_{ij} &= \frac{\sigma_{b,i}^2}{\sigma_{b,i}^2 + \hat\sigma^2_{\epsilon,ij}} \\
    &= \frac{\exp(\Vector{X}_i\Vector{\eta}_{\bullet 1})^2}{\exp(\Vector{X}_i\Vector{\eta}_{\bullet 1})^2 + \exp(\Vector{x}_{ij}\Vector{\gamma}_i)^2},
\end{align*}
where $\Vector{\eta}_{\bullet 1}$ refers to the first column of $\Vector{\eta}$, which specifically contains the predictive coefficients for the group mean standard deviation (i.e., for $\sigma_{b,i}$).

The model implemented by \texttt{ICCier} employs a maximal structure, such that every level 2 variable predicts each level 1 coefficient.
This allows researchers to explore the impact of level 2 variables on the level 1 scale model.
In practice, this does not affect the estimated ICCs.
The ICC calculation only requires the predicted between-group and within-group variance.
If one only had a level 1 scale model, with no level 2 predictors, then the random effect variances would be larger than with level 2 covariates.
Consequently, the random effects would change, but the predicted within-person variance would be the same.
Therefore, although the model is maximal, the dense $\Vector{\Gamma}$ matrix provides additional insight into varying ICCs without affecting the estimated ICCs themselves.
\subsubsection{Priors}
Broadly, there are four sets of parameters for which priors must be defined: Fixed location intercept ($\beta_0$), fixed scale coefficients ($\Vector{\Gamma}$), between-person scale coefficients ($\Vector{\eta}$), and the random effect correlations ($\Vector{\Omega}$).
In practice, one should choose priors based on the a-priori known characteristics of the data, such that the priors imply reasonable expected values and variances for the given scenario \citep{Gelman2017_prior_likelihood}.
Nevertheless, the following priors were specified to accommodate a wide range of possible data.
\begin{align*}
    \beta_0 &\sim \mathcal{N}(0,10) \\
    \Gamma_{pq} &\sim \mathcal{ST}(\nu = 3, \mu = 0, \sigma = 5), \forall p,q \\
    \eta_{pq} &\sim \mathcal{ST}(\nu = 3, \mu = 0, \sigma = 5), \forall p,q \\
    \Vector{\Omega} &\sim LKJ(1)
\end{align*}
Note that $\Gamma_{pq}$ and $\eta_{pq}$ represent elements in the respective $\Vector{\Gamma}$ and $\Vector{\eta}$ coefficient matrices.
Each element in these coefficient matrices is given a heavy-tailed Student T prior.
%We recommend using a heavy-tailed prior for scale model parameters.
The heavy-tailed prior accommodates variances approaching zero better than a normal distribution permits.
In our testing of this model, between-group variances in particular may be small or effectively zero, and the wide-tailed priors effectively attenuated any sampling problems.
The LKJ prior is a spherical prior over correlation matrices that takes a single parameter.
We set the parameter to one, implying a uniform prior over correlation matrices [@lewandowski2009b].

# Function Overview

## `ICCier`
## `summary`
## `predict` and `fitted`
## `ranef` and `coef`
## `loo`

# Examples

## Unconditional, Intercept-only

## Unconditional, Scale Model

## Conditional, Intercept-only

## Conditional, Scale Model

## Level 2 Variables

# Model Comparison

# Best Practices

## Diagnostic Failures and You

## Scaling and Centering

## Pre-Filtering (Self: as in, using complete cases only, so fitted can be combined easily)

# References
